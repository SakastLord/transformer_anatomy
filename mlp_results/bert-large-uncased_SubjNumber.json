{"0_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 78.05, "acc": 76.98}, "1_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 80.48, "acc": 78.6}, "2_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 80.84, "acc": 80.38}, "3_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 81.4, "acc": 81.31}, "4_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 80.25, "acc": 79.28}, "5_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 80.98, "acc": 80.27}, "6_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 81.79, "acc": 80.39}, "7_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 81.91, "acc": 80.9}, "8_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 82.09, "acc": 81.49}, "9_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 83.71, "acc": 83.0}, "10_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 84.04, "acc": 83.29}, "11_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 86.25, "acc": 85.62}, "12_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 86.83, "acc": 86.6}, "13_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 88.12, "acc": 88.74}, "14_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 88.56, "acc": 89.38}, "15_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 87.26, "acc": 87.56}, "16_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 86.37, "acc": 86.99}, "17_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 86.24, "acc": 86.75}, "18_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 85.44, "acc": 86.11}, "19_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 84.69, "acc": 85.08}, "20_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 83.61, "acc": 83.37}, "21_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 82.61, "acc": 82.77}, "22_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 81.54, "acc": 81.52}, "23_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 81.08, "acc": 81.43}, "0_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.23, "acc": 69.55}, "1_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.11, "acc": 68.15}, "2_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.57, "acc": 65.64}, "3_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 66.52, "acc": 66.38}, "4_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.21, "acc": 64.56}, "5_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.32, "acc": 64.95}, "6_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.35, "acc": 64.61}, "7_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.81, "acc": 65.94}, "8_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.32, "acc": 66.45}, "9_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.98, "acc": 68.59}, "10_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.65, "acc": 68.17}, "11_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.92, "acc": 70.39}, "12_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.33, "acc": 70.98}, "13_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.67, "acc": 71.68}, "14_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.71, "acc": 74.13}, "15_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.14, "acc": 71.3}, "16_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.25, "acc": 70.44}, "17_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.08, "acc": 69.89}, "18_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.98, "acc": 70.82}, "19_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.38, "acc": 68.78}, "20_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.27, "acc": 67.85}, "21_0": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.97, "acc": 66.89}, "22_0": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.79, "acc": 66.08}, "23_0": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.3, "acc": 65.18}, "0_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.62, "acc": 69.22}, "1_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.46, "acc": 69.65}, "2_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.29, "acc": 69.16}, "3_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.37, "acc": 69.98}, "4_1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 63.38, "acc": 64.33}, "5_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 63.8, "acc": 67.0}, "6_1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.43, "acc": 68.08}, "7_1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.83, "acc": 67.72}, "8_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.44, "acc": 66.7}, "9_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.62, "acc": 68.05}, "10_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.34, "acc": 67.8}, "11_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.85, "acc": 68.75}, "12_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.66, "acc": 72.43}, "13_1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.55, "acc": 72.86}, "14_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.57, "acc": 74.37}, "15_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.8, "acc": 71.99}, "16_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.04, "acc": 71.32}, "17_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 71.32, "acc": 70.47}, "18_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.82, "acc": 71.69}, "19_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 70.69, "acc": 70.19}, "20_1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.75, "acc": 68.17}, "21_1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.1, "acc": 67.34}, "22_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.96, "acc": 66.37}, "23_1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.38, "acc": 65.0}, "0_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.87, "acc": 67.74}, "1_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.63, "acc": 66.26}, "2_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.18, "acc": 66.34}, "3_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 65.56, "acc": 65.98}, "4_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.17, "acc": 66.24}, "5_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.76, "acc": 66.54}, "6_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.59, "acc": 69.58}, "7_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.44, "acc": 66.39}, "8_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.85, "acc": 68.04}, "9_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.91, "acc": 67.96}, "10_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.91, "acc": 66.5}, "11_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.63, "acc": 69.76}, "12_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.56, "acc": 71.38}, "13_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.07, "acc": 72.67}, "14_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.23, "acc": 74.25}, "15_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.51, "acc": 71.86}, "16_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.23, "acc": 71.25}, "17_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.52, "acc": 69.46}, "18_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.93, "acc": 68.73}, "19_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.86, "acc": 69.08}, "20_2": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.11, "acc": 69.56}, "21_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.54, "acc": 68.71}, "22_2": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.63, "acc": 66.5}, "23_2": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.02, "acc": 66.07}, "0_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.61, "acc": 68.05}, "1_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.79, "acc": 66.66}, "2_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 67.39, "acc": 67.32}, "3_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.04, "acc": 69.06}, "4_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 67.76, "acc": 66.6}, "5_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.76, "acc": 67.03}, "6_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.23, "acc": 67.2}, "7_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 65.03, "acc": 65.13}, "8_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.92, "acc": 66.31}, "9_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.97, "acc": 68.67}, "10_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.23, "acc": 69.3}, "11_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.73, "acc": 69.55}, "12_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.03, "acc": 72.61}, "13_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.23, "acc": 70.99}, "14_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 77.19, "acc": 77.21}, "15_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.61, "acc": 74.09}, "16_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.13, "acc": 73.0}, "17_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.27, "acc": 73.54}, "18_3": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.94, "acc": 70.95}, "19_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.58, "acc": 70.16}, "20_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.95, "acc": 68.97}, "21_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.78, "acc": 67.95}, "22_3": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.39, "acc": 67.43}, "23_3": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.57, "acc": 66.67}, "0_4": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.61, "acc": 68.21}, "1_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 68.92, "acc": 68.01}, "2_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.87, "acc": 67.84}, "3_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.08, "acc": 68.36}, "4_4": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 65.27, "acc": 64.35}, "5_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.65, "acc": 64.1}, "6_4": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.91, "acc": 66.46}, "7_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.99, "acc": 66.45}, "8_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.72, "acc": 68.72}, "9_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.09, "acc": 69.05}, "10_4": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.44, "acc": 67.8}, "11_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.24, "acc": 69.08}, "12_4": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.61, "acc": 71.25}, "13_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.41, "acc": 72.06}, "14_4": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 75.88, "acc": 76.16}, "15_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.37, "acc": 73.04}, "16_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.17, "acc": 72.01}, "17_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.37, "acc": 69.38}, "18_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.11, "acc": 70.58}, "19_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.5, "acc": 70.0}, "20_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.48, "acc": 68.81}, "21_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.78, "acc": 67.41}, "22_4": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.32, "acc": 66.92}, "23_4": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.36, "acc": 65.67}, "0_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 69.03, "acc": 68.15}, "1_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.39, "acc": 67.1}, "2_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.04, "acc": 66.64}, "3_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 67.45, "acc": 66.32}, "4_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.9, "acc": 63.84}, "5_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.53, "acc": 65.46}, "6_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.83, "acc": 66.85}, "7_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.79, "acc": 67.41}, "8_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.34, "acc": 67.44}, "9_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.43, "acc": 68.18}, "10_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.58, "acc": 68.59}, "11_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.44, "acc": 69.35}, "12_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.08, "acc": 71.53}, "13_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.09, "acc": 72.65}, "14_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.7, "acc": 74.72}, "15_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.62, "acc": 71.79}, "16_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.25, "acc": 72.42}, "17_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.6, "acc": 71.21}, "18_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.44, "acc": 70.07}, "19_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.29, "acc": 70.01}, "20_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.25, "acc": 68.74}, "21_5": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.52, "acc": 67.6}, "22_5": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.65, "acc": 67.2}, "23_5": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.15, "acc": 67.63}, "0_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.63, "acc": 69.01}, "1_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.94, "acc": 67.37}, "2_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.95, "acc": 66.48}, "3_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.62, "acc": 65.52}, "4_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.59, "acc": 64.33}, "5_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.78, "acc": 66.01}, "6_6": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.05, "acc": 66.36}, "7_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.34, "acc": 65.77}, "8_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.69, "acc": 65.15}, "9_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.74, "acc": 67.25}, "10_6": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.28, "acc": 68.33}, "11_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.28, "acc": 71.12}, "12_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.11, "acc": 71.6}, "13_6": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.43, "acc": 72.24}, "14_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 74.92, "acc": 75.16}, "15_6": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.18, "acc": 72.62}, "16_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.7, "acc": 70.96}, "17_6": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 72.04, "acc": 70.43}, "18_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.32, "acc": 70.66}, "19_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 72.77, "acc": 71.2}, "20_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 70.88, "acc": 70.07}, "21_6": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.94, "acc": 68.89}, "22_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.36, "acc": 68.32}, "23_6": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.82, "acc": 66.74}, "0_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.11, "acc": 69.06}, "1_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.95, "acc": 66.92}, "2_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.04, "acc": 68.22}, "3_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 69.58, "acc": 68.71}, "4_7": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.31, "acc": 66.27}, "5_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.32, "acc": 66.07}, "6_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.45, "acc": 63.49}, "7_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 63.78, "acc": 65.25}, "8_7": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.09, "acc": 63.96}, "9_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.73, "acc": 65.94}, "10_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.86, "acc": 67.28}, "11_7": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.11, "acc": 70.12}, "12_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.92, "acc": 72.41}, "13_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.65, "acc": 74.18}, "14_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 76.84, "acc": 77.08}, "15_7": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 75.05, "acc": 74.05}, "16_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.27, "acc": 73.89}, "17_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 72.87, "acc": 72.12}, "18_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 72.93, "acc": 72.74}, "19_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.7, "acc": 71.29}, "20_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 70.23, "acc": 69.84}, "21_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.83, "acc": 67.31}, "22_7": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 65.39, "acc": 66.38}, "23_7": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 63.82, "acc": 65.67}, "0_8": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.08, "acc": 67.76}, "1_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.51, "acc": 69.21}, "2_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 64.53, "acc": 65.77}, "3_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.74, "acc": 65.62}, "4_8": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.24, "acc": 64.62}, "5_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.88, "acc": 64.75}, "6_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.05, "acc": 66.19}, "7_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.65, "acc": 65.29}, "8_8": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.89, "acc": 66.42}, "9_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.23, "acc": 67.5}, "10_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.28, "acc": 68.95}, "11_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.51, "acc": 69.39}, "12_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.52, "acc": 71.5}, "13_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.65, "acc": 72.56}, "14_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.62, "acc": 74.39}, "15_8": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.74, "acc": 72.45}, "16_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.38, "acc": 71.12}, "17_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.64, "acc": 69.88}, "18_8": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.28, "acc": 69.27}, "19_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.84, "acc": 68.68}, "20_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.08, "acc": 67.87}, "21_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.69, "acc": 66.24}, "22_8": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.68, "acc": 66.57}, "23_8": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.03, "acc": 65.35}, "0_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.32, "acc": 67.56}, "1_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.27, "acc": 66.5}, "2_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.0, "acc": 68.21}, "3_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.23, "acc": 67.12}, "4_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.52, "acc": 66.4}, "5_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.83, "acc": 64.35}, "6_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.14, "acc": 65.99}, "7_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.48, "acc": 65.4}, "8_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.74, "acc": 66.15}, "9_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.5, "acc": 67.98}, "10_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.83, "acc": 69.22}, "11_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.67, "acc": 71.0}, "12_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.84, "acc": 72.56}, "13_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.68, "acc": 73.51}, "14_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 76.02, "acc": 76.01}, "15_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 73.75, "acc": 73.95}, "16_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.75, "acc": 73.75}, "17_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.41, "acc": 71.8}, "18_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.43, "acc": 72.03}, "19_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.01, "acc": 71.41}, "20_9": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.47, "acc": 70.48}, "21_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.06, "acc": 69.25}, "22_9": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.42, "acc": 68.45}, "23_9": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.11, "acc": 67.65}, "0_10": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.47, "acc": 66.92}, "1_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.84, "acc": 65.75}, "2_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.69, "acc": 67.68}, "3_10": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.43, "acc": 67.58}, "4_10": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.24, "acc": 65.27}, "5_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.77, "acc": 65.36}, "6_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.85, "acc": 67.95}, "7_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.8, "acc": 68.16}, "8_10": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.25, "acc": 67.47}, "9_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.85, "acc": 68.45}, "10_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.35, "acc": 69.92}, "11_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.7, "acc": 71.42}, "12_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.05, "acc": 72.74}, "13_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.85, "acc": 74.67}, "14_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.83, "acc": 74.95}, "15_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.08, "acc": 72.38}, "16_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.21, "acc": 70.48}, "17_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.63, "acc": 70.5}, "18_10": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.28, "acc": 70.63}, "19_10": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.8, "acc": 71.05}, "20_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 70.58, "acc": 70.7}, "21_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.57, "acc": 69.71}, "22_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.82, "acc": 68.32}, "23_10": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.82, "acc": 67.22}, "0_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.01, "acc": 67.77}, "1_11": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.55, "acc": 69.28}, "2_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.63, "acc": 67.67}, "3_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.99, "acc": 67.97}, "4_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.51, "acc": 65.14}, "5_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.52, "acc": 66.83}, "6_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.94, "acc": 67.91}, "7_11": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.49, "acc": 67.42}, "8_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.87, "acc": 68.36}, "9_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.92, "acc": 68.86}, "10_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.04, "acc": 68.08}, "11_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.62, "acc": 71.57}, "12_11": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.58, "acc": 72.84}, "13_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.27, "acc": 73.16}, "14_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 75.36, "acc": 76.53}, "15_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.66, "acc": 74.06}, "16_11": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.2, "acc": 73.59}, "17_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 72.54, "acc": 73.63}, "18_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.45, "acc": 73.12}, "19_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.29, "acc": 73.52}, "20_11": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.22, "acc": 72.16}, "21_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.44, "acc": 70.45}, "22_11": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 68.62, "acc": 68.09}, "23_11": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.21, "acc": 67.15}, "0_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.25, "acc": 67.59}, "1_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.39, "acc": 69.15}, "2_12": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.7, "acc": 67.47}, "3_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.09, "acc": 65.26}, "4_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.59, "acc": 66.09}, "5_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.42, "acc": 65.47}, "6_12": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.85, "acc": 69.27}, "7_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.88, "acc": 69.03}, "8_12": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.01, "acc": 67.58}, "9_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.66, "acc": 69.01}, "10_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.79, "acc": 68.5}, "11_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.2, "acc": 70.66}, "12_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.66, "acc": 70.67}, "13_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.28, "acc": 73.83}, "14_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 76.21, "acc": 76.08}, "15_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.65, "acc": 74.56}, "16_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 73.59, "acc": 73.54}, "17_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.47, "acc": 71.05}, "18_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 72.51, "acc": 71.39}, "19_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 71.8, "acc": 70.59}, "20_12": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 71.03, "acc": 69.81}, "21_12": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.79, "acc": 69.6}, "22_12": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.28, "acc": 67.9}, "23_12": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.02, "acc": 66.73}, "0_13": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.9, "acc": 70.43}, "1_13": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.77, "acc": 67.51}, "2_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 69.45, "acc": 68.41}, "3_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.76, "acc": 68.7}, "4_13": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.54, "acc": 67.27}, "5_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.07, "acc": 65.07}, "6_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.72, "acc": 67.03}, "7_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.38, "acc": 67.73}, "8_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.95, "acc": 67.74}, "9_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.42, "acc": 68.57}, "10_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.83, "acc": 69.84}, "11_13": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.48, "acc": 71.94}, "12_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.81, "acc": 73.74}, "13_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 75.23, "acc": 74.29}, "14_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 77.33, "acc": 77.77}, "15_13": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.4, "acc": 74.34}, "16_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.58, "acc": 72.87}, "17_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.47, "acc": 72.35}, "18_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.96, "acc": 71.26}, "19_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.99, "acc": 71.74}, "20_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.07, "acc": 70.28}, "21_13": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.0, "acc": 69.81}, "22_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.27, "acc": 68.34}, "23_13": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.63, "acc": 67.75}, "0_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.16, "acc": 66.3}, "1_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.79, "acc": 65.29}, "2_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 64.67, "acc": 64.12}, "3_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 65.95, "acc": 65.79}, "4_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 63.37, "acc": 63.63}, "5_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.5, "acc": 64.28}, "6_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.61, "acc": 66.36}, "7_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.86, "acc": 65.67}, "8_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.87, "acc": 65.92}, "9_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.47, "acc": 66.89}, "10_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.79, "acc": 67.05}, "11_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.05, "acc": 69.45}, "12_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.95, "acc": 71.27}, "13_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.59, "acc": 72.06}, "14_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.01, "acc": 73.61}, "15_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.77, "acc": 70.17}, "16_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.12, "acc": 70.46}, "17_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.4, "acc": 70.3}, "18_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.4, "acc": 69.68}, "19_14": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.56, "acc": 69.99}, "20_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.71, "acc": 69.51}, "21_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.4, "acc": 68.93}, "22_14": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.1, "acc": 67.79}, "23_14": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.64, "acc": 67.34}, "0_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.46, "acc": 68.73}, "1_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 65.99, "acc": 66.64}, "2_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.64, "acc": 65.18}, "3_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.84, "acc": 65.94}, "4_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 64.67, "acc": 64.22}, "5_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 65.16, "acc": 64.4}, "6_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.94, "acc": 67.42}, "7_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.3, "acc": 65.82}, "8_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 66.42, "acc": 66.68}, "9_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 67.96, "acc": 67.26}, "10_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 67.8, "acc": 68.24}, "11_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.76, "acc": 68.72}, "12_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.86, "acc": 71.36}, "13_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 72.35, "acc": 73.53}, "14_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 74.78, "acc": 74.29}, "15_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 71.79, "acc": 73.04}, "16_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 70.05, "acc": 70.39}, "17_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 69.26, "acc": 69.69}, "18_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.54, "acc": 69.73}, "19_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 69.26, "acc": 68.05}, "20_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 68.89, "acc": 67.69}, "21_15": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 68.11, "acc": 66.46}, "22_15": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.89, "acc": 65.88}, "23_15": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 66.05, "acc": 65.05}}
{"0_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.29, "acc": 2.34}, "1_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.65, "acc": 11.62}, "2_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.11, "acc": 12.96}, "0_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.81, "acc": 1.91}, "1_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 5.22, "acc": 5.19}, "3_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.94, "acc": 31.52}, "2_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.22, "acc": 7.4}, "4_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 31.59, "acc": 32.03}, "5_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.79, "acc": 27.59}, "3_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.68, "acc": 29.09}, "6_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.66, "acc": 23.84}, "4_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.55, "acc": 25.86}, "7_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.27, "acc": 19.06}, "5_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.91, "acc": 19.06}, "8_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 20.03, "acc": 20.04}, "6_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.54, "acc": 11.29}, "9_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.99, "acc": 19.9}, "7_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.27, "acc": 9.33}, "10_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.61, "acc": 23.82}, "8_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.17, "acc": 8.89}, "11_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.46, "acc": 31.0}, "9_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.15, "acc": 8.86}, "0_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.46, "acc": 1.3}, "10_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.83, "acc": 10.82}, "1_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.57, "acc": 4.33}, "11_6": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.83, "acc": 14.32}, "2_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 6.7, "acc": 6.93}, "0_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.78, "acc": 1.83}, "3_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.56, "acc": 26.21}, "1_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.86, "acc": 4.82}, "4_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.32, "acc": 25.05}, "2_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.23, "acc": 8.37}, "5_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.77, "acc": 18.91}, "3_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.31, "acc": 28.01}, "6_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.78, "acc": 11.66}, "4_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.34, "acc": 25.13}, "7_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.04, "acc": 8.68}, "5_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.65, "acc": 17.86}, "8_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.17, "acc": 9.27}, "6_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.13, "acc": 11.0}, "9_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.04, "acc": 9.23}, "7_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.12, "acc": 8.68}, "10_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.45, "acc": 10.78}, "8_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.69, "acc": 9.15}, "11_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.57, "acc": 14.45}, "9_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.48, "acc": 9.15}, "0_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.65, "acc": 1.7}, "10_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.76, "acc": 10.4}, "1_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.71, "acc": 4.91}, "11_7": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.18, "acc": 14.0}, "2_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 6.76, "acc": 6.24}, "0_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.59, "acc": 1.59}, "3_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.6, "acc": 28.54}, "1_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.88, "acc": 4.84}, "4_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.9, "acc": 25.96}, "2_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.78, "acc": 7.92}, "5_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.7, "acc": 19.52}, "3_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.69, "acc": 29.02}, "6_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.74, "acc": 11.96}, "4_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.06, "acc": 26.27}, "7_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.41, "acc": 9.71}, "5_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.15, "acc": 19.59}, "8_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.41, "acc": 9.76}, "6_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.83, "acc": 11.76}, "9_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.09, "acc": 9.17}, "7_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.3, "acc": 9.46}, "10_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.89, "acc": 10.53}, "8_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.32, "acc": 9.48}, "11_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.04, "acc": 14.41}, "9_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.2, "acc": 9.17}, "0_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.54, "acc": 1.58}, "10_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.61, "acc": 10.63}, "1_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.07, "acc": 4.12}, "11_8": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.64, "acc": 14.46}, "2_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.12, "acc": 7.21}, "0_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.81, "acc": 1.91}, "1_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.67, "acc": 4.7}, "3_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.26, "acc": 28.57}, "2_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.45, "acc": 7.84}, "4_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.39, "acc": 25.92}, "5_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.49, "acc": 19.97}, "3_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.18, "acc": 27.43}, "6_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.71, "acc": 11.99}, "4_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.21, "acc": 26.17}, "7_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.61, "acc": 9.44}, "5_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.36, "acc": 19.78}, "8_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.86, "acc": 9.84}, "6_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 12.21, "acc": 12.37}, "9_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.25, "acc": 9.27}, "7_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.49, "acc": 9.53}, "10_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.86, "acc": 10.92}, "8_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.12, "acc": 9.17}, "11_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.06, "acc": 13.82}, "9_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.07, "acc": 9.01}, "0_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.9, "acc": 1.98}, "10_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.47, "acc": 10.63}, "1_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 6.15, "acc": 6.66}, "11_9": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.44, "acc": 13.6}, "2_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.53, "acc": 7.82}, "0_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.65, "acc": 1.76}, "1_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.38, "acc": 4.4}, "3_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.13, "acc": 28.24}, "2_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 6.89, "acc": 6.91}, "4_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.18, "acc": 24.97}, "3_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.64, "acc": 28.8}, "5_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.87, "acc": 17.35}, "6_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.92, "acc": 10.74}, "4_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.83, "acc": 26.36}, "7_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.98, "acc": 9.18}, "5_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.93, "acc": 18.45}, "8_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.31, "acc": 9.4}, "6_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.37, "acc": 12.15}, "9_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.98, "acc": 9.13}, "7_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.79, "acc": 9.26}, "10_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.62, "acc": 10.24}, "8_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.24, "acc": 9.41}, "11_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.48, "acc": 13.19}, "9_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.06, "acc": 9.23}, "0_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.1, "acc": 1.01}, "10_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.94, "acc": 10.7}, "1_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 3.15, "acc": 3.44}, "11_10": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.55, "acc": 14.11}, "2_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 3.84, "acc": 3.55}, "0_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.57, "acc": 1.69}, "3_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.61, "acc": 24.17}, "1_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 4.99, "acc": 5.22}, "4_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.09, "acc": 22.74}, "2_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.52, "acc": 7.83}, "5_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.86, "acc": 15.95}, "6_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.27, "acc": 9.97}, "3_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.08, "acc": 28.36}, "7_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.44, "acc": 8.27}, "4_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.08, "acc": 25.26}, "8_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.83, "acc": 8.9}, "5_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.74, "acc": 19.04}, "9_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.5, "acc": 8.64}, "6_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.69, "acc": 11.89}, "10_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.32, "acc": 10.04}, "7_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.05, "acc": 9.39}, "11_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.47, "acc": 13.34}, "8_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.23, "acc": 9.34}, "0_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.65, "acc": 1.66}, "9_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.41, "acc": 9.04}, "1_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 5.02, "acc": 4.86}, "10_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.69, "acc": 10.6}, "2_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.09, "acc": 6.78}, "11_11": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.49, "acc": 13.26}, "3_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.0, "acc": 29.3}, "4_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 24.59, "acc": 25.11}, "5_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.89, "acc": 19.19}, "6_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.54, "acc": 11.68}, "7_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.64, "acc": 8.45}, "8_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.69, "acc": 8.47}, "9_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.73, "acc": 8.1}, "10_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.6, "acc": 10.4}, "11_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.34, "acc": 14.09}}
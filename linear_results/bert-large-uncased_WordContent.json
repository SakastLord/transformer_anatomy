{"0_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": -1, "head_size": 64, "devacc": 4.39, "acc": 4.44}, "1_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": -1, "head_size": 64, "devacc": 31.57, "acc": 32.22}, "2_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": -1, "head_size": 64, "devacc": 27.72, "acc": 28.07}, "3_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": -1, "head_size": 64, "devacc": 24.4, "acc": 24.41}, "4_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": -1, "head_size": 64, "devacc": 26.44, "acc": 26.21}, "5_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": -1, "head_size": 64, "devacc": 27.19, "acc": 27.73}, "0_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 0, "head_size": 64, "devacc": 2.28, "acc": 2.13}, "0_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 1, "head_size": 64, "devacc": 2.02, "acc": 2.11}, "0_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 2, "head_size": 64, "devacc": 0.96, "acc": 0.94}, "0_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 3, "head_size": 64, "devacc": 1.89, "acc": 1.86}, "0_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 4, "head_size": 64, "devacc": 2.12, "acc": 2.08}, "0_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 5, "head_size": 64, "devacc": 2.17, "acc": 2.15}, "0_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 6, "head_size": 64, "devacc": 2.22, "acc": 2.28}, "0_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 7, "head_size": 64, "devacc": 2.18, "acc": 2.22}, "0_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 8, "head_size": 64, "devacc": 2.18, "acc": 2.12}, "0_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 9, "head_size": 64, "devacc": 2.05, "acc": 2.05}, "0_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 10, "head_size": 64, "devacc": 2.25, "acc": 2.39}, "0_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 11, "head_size": 64, "devacc": 2.43, "acc": 2.53}, "1_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 0, "head_size": 64, "devacc": 17.09, "acc": 17.35}, "1_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 1, "head_size": 64, "devacc": 16.2, "acc": 16.23}, "1_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 2, "head_size": 64, "devacc": 10.5, "acc": 10.66}, "1_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 3, "head_size": 64, "devacc": 17.97, "acc": 18.28}, "1_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 4, "head_size": 64, "devacc": 16.91, "acc": 16.92}, "1_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 5, "head_size": 64, "devacc": 17.76, "acc": 18.21}, "1_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 6, "head_size": 64, "devacc": 18.09, "acc": 18.79}, "1_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 7, "head_size": 64, "devacc": 18.66, "acc": 18.61}, "1_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 8, "head_size": 64, "devacc": 18.11, "acc": 18.29}, "1_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 9, "head_size": 64, "devacc": 17.45, "acc": 17.89}, "1_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 10, "head_size": 64, "devacc": 16.22, "acc": 16.32}, "1_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 11, "head_size": 64, "devacc": 18.44, "acc": 18.46}, "2_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 0, "head_size": 64, "devacc": 15.22, "acc": 15.74}, "2_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 1, "head_size": 64, "devacc": 14.29, "acc": 13.91}, "2_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 2, "head_size": 64, "devacc": 9.06, "acc": 9.28}, "2_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 3, "head_size": 64, "devacc": 16.56, "acc": 17.01}, "2_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 4, "head_size": 64, "devacc": 15.19, "acc": 14.87}, "2_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 5, "head_size": 64, "devacc": 15.73, "acc": 16.09}, "2_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 6, "head_size": 64, "devacc": 16.96, "acc": 16.7}, "2_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 7, "head_size": 64, "devacc": 16.23, "acc": 16.27}, "2_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 8, "head_size": 64, "devacc": 16.3, "acc": 16.99}, "2_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 9, "head_size": 64, "devacc": 16.19, "acc": 16.58}, "2_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 10, "head_size": 64, "devacc": 15.12, "acc": 15.46}, "2_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 11, "head_size": 64, "devacc": 16.48, "acc": 16.46}, "3_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 0, "head_size": 64, "devacc": 13.83, "acc": 13.72}, "3_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 1, "head_size": 64, "devacc": 13.15, "acc": 12.54}, "3_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 2, "head_size": 64, "devacc": 7.61, "acc": 7.45}, "3_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 3, "head_size": 64, "devacc": 14.35, "acc": 14.66}, "3_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 4, "head_size": 64, "devacc": 13.72, "acc": 13.67}, "3_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 5, "head_size": 64, "devacc": 14.88, "acc": 14.72}, "3_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 6, "head_size": 64, "devacc": 14.35, "acc": 14.35}, "3_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 7, "head_size": 64, "devacc": 13.83, "acc": 13.67}, "3_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 8, "head_size": 64, "devacc": 13.38, "acc": 13.5}, "3_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 9, "head_size": 64, "devacc": 13.96, "acc": 14.32}, "3_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 10, "head_size": 64, "devacc": 14.16, "acc": 13.03}, "3_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 11, "head_size": 64, "devacc": 13.58, "acc": 13.66}, "4_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 0, "head_size": 64, "devacc": 17.97, "acc": 18.71}, "4_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 1, "head_size": 64, "devacc": 16.86, "acc": 16.79}, "4_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 2, "head_size": 64, "devacc": 13.8, "acc": 13.54}, "4_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 3, "head_size": 64, "devacc": 16.38, "acc": 16.16}, "4_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 4, "head_size": 64, "devacc": 18.68, "acc": 18.28}, "4_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 5, "head_size": 64, "devacc": 19.0, "acc": 18.59}, "4_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 6, "head_size": 64, "devacc": 18.31, "acc": 18.41}, "4_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 7, "head_size": 64, "devacc": 17.0, "acc": 17.59}, "4_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 8, "head_size": 64, "devacc": 19.11, "acc": 19.25}, "4_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 9, "head_size": 64, "devacc": 17.48, "acc": 17.85}, "4_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 10, "head_size": 64, "devacc": 18.54, "acc": 18.09}, "4_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 11, "head_size": 64, "devacc": 18.84, "acc": 18.56}, "5_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 0, "head_size": 64, "devacc": 23.26, "acc": 23.67}, "5_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 1, "head_size": 64, "devacc": 22.08, "acc": 22.28}, "5_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 2, "head_size": 64, "devacc": 21.0, "acc": 20.84}, "5_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 3, "head_size": 64, "devacc": 20.16, "acc": 20.79}, "5_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 4, "head_size": 64, "devacc": 22.2, "acc": 22.49}, "5_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 5, "head_size": 64, "devacc": 24.02, "acc": 23.25}, "5_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 6, "head_size": 64, "devacc": 23.36, "acc": 23.3}, "5_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 7, "head_size": 64, "devacc": 21.76, "acc": 21.97}, "5_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 8, "head_size": 64, "devacc": 22.96, "acc": 23.38}, "5_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 9, "head_size": 64, "devacc": 22.64, "acc": 22.5}, "5_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 10, "head_size": 64, "devacc": 23.46, "acc": 23.77}, "5_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 11, "head_size": 64, "devacc": 23.58, "acc": 23.66}, "6_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": -1, "head_size": 64, "devacc": 27.62, "acc": 28.42}, "6_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 0, "head_size": 64, "devacc": 28.04, "acc": 27.68}, "6_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 1, "head_size": 64, "devacc": 27.49, "acc": 26.65}, "6_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 2, "head_size": 64, "devacc": 27.37, "acc": 27.76}, "6_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 3, "head_size": 64, "devacc": 25.15, "acc": 25.71}, "6_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 4, "head_size": 64, "devacc": 26.75, "acc": 27.23}, "6_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 5, "head_size": 64, "devacc": 28.11, "acc": 28.1}, "6_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 6, "head_size": 64, "devacc": 27.77, "acc": 27.94}, "6_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 7, "head_size": 64, "devacc": 23.68, "acc": 23.67}, "6_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 8, "head_size": 64, "devacc": 27.7, "acc": 27.85}, "6_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 9, "head_size": 64, "devacc": 27.52, "acc": 27.48}, "6_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 10, "head_size": 64, "devacc": 26.45, "acc": 25.82}, "6_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 11, "head_size": 64, "devacc": 27.3, "acc": 27.23}, "7_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": -1, "head_size": 64, "devacc": 25.32, "acc": 24.79}, "7_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 0, "head_size": 64, "devacc": 29.19, "acc": 28.49}, "7_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 1, "head_size": 64, "devacc": 27.39, "acc": 26.83}, "7_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 2, "head_size": 64, "devacc": 27.56, "acc": 27.71}, "7_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 3, "head_size": 64, "devacc": 27.06, "acc": 26.13}, "7_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 4, "head_size": 64, "devacc": 28.12, "acc": 27.97}, "7_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 5, "head_size": 64, "devacc": 28.36, "acc": 27.72}, "7_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 6, "head_size": 64, "devacc": 29.01, "acc": 28.5}, "7_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 7, "head_size": 64, "devacc": 23.5, "acc": 22.98}, "7_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 8, "head_size": 64, "devacc": 28.45, "acc": 28.44}, "7_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 9, "head_size": 64, "devacc": 28.4, "acc": 28.11}, "7_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 10, "head_size": 64, "devacc": 27.9, "acc": 27.6}, "7_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 11, "head_size": 64, "devacc": 28.17, "acc": 27.73}, "8_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": -1, "head_size": 64, "devacc": 24.25, "acc": 24.42}, "8_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 0, "head_size": 64, "devacc": 28.53, "acc": 28.29}, "8_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 1, "head_size": 64, "devacc": 26.85, "acc": 25.91}, "8_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 2, "head_size": 64, "devacc": 27.58, "acc": 27.54}, "8_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 3, "head_size": 64, "devacc": 26.59, "acc": 26.86}, "8_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 4, "head_size": 64, "devacc": 26.82, "acc": 26.6}, "8_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 5, "head_size": 64, "devacc": 27.82, "acc": 27.59}, "8_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 6, "head_size": 64, "devacc": 28.71, "acc": 28.1}, "8_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 7, "head_size": 64, "devacc": 23.82, "acc": 22.88}, "8_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 8, "head_size": 64, "devacc": 28.08, "acc": 27.35}, "8_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 9, "head_size": 64, "devacc": 27.35, "acc": 27.28}, "8_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 10, "head_size": 64, "devacc": 27.34, "acc": 26.53}, "8_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 11, "head_size": 64, "devacc": 28.13, "acc": 27.94}, "9_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": -1, "head_size": 64, "devacc": 26.69, "acc": 26.56}, "9_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 0, "head_size": 64, "devacc": 28.65, "acc": 28.86}, "9_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 1, "head_size": 64, "devacc": 28.66, "acc": 27.82}, "9_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 2, "head_size": 64, "devacc": 28.55, "acc": 28.68}, "9_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 3, "head_size": 64, "devacc": 28.83, "acc": 28.55}, "9_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 4, "head_size": 64, "devacc": 28.79, "acc": 28.54}, "9_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 5, "head_size": 64, "devacc": 28.67, "acc": 29.0}, "9_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 6, "head_size": 64, "devacc": 28.84, "acc": 28.57}, "9_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 7, "head_size": 64, "devacc": 24.73, "acc": 24.66}, "9_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 8, "head_size": 64, "devacc": 29.78, "acc": 29.48}, "9_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 9, "head_size": 64, "devacc": 28.92, "acc": 28.68}, "9_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 10, "head_size": 64, "devacc": 29.25, "acc": 29.22}, "9_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 11, "head_size": 64, "devacc": 28.73, "acc": 28.71}, "10_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": -1, "head_size": 64, "devacc": 27.91, "acc": 28.82}, "10_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 0, "head_size": 64, "devacc": 30.07, "acc": 29.88}, "10_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 1, "head_size": 64, "devacc": 28.4, "acc": 28.35}, "10_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 2, "head_size": 64, "devacc": 29.62, "acc": 29.58}, "10_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 3, "head_size": 64, "devacc": 29.74, "acc": 29.07}, "10_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 4, "head_size": 64, "devacc": 29.01, "acc": 29.51}, "10_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 5, "head_size": 64, "devacc": 29.1, "acc": 29.37}, "10_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 6, "head_size": 64, "devacc": 29.62, "acc": 29.26}, "10_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 7, "head_size": 64, "devacc": 26.11, "acc": 26.29}, "10_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 8, "head_size": 64, "devacc": 29.02, "acc": 29.67}, "10_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 9, "head_size": 64, "devacc": 29.94, "acc": 30.09}, "10_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 10, "head_size": 64, "devacc": 29.45, "acc": 29.14}, "10_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 11, "head_size": 64, "devacc": 29.64, "acc": 29.58}, "11_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": -1, "head_size": 64, "devacc": 25.54, "acc": 26.04}, "11_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 0, "head_size": 64, "devacc": 27.39, "acc": 27.94}, "11_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 1, "head_size": 64, "devacc": 25.98, "acc": 26.2}, "11_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 2, "head_size": 64, "devacc": 27.5, "acc": 27.66}, "11_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 3, "head_size": 64, "devacc": 27.51, "acc": 27.66}, "11_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 4, "head_size": 64, "devacc": 27.83, "acc": 27.83}, "11_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 5, "head_size": 64, "devacc": 27.04, "acc": 27.9}, "11_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 6, "head_size": 64, "devacc": 27.51, "acc": 27.64}, "11_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 7, "head_size": 64, "devacc": 24.02, "acc": 24.22}, "11_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 8, "head_size": 64, "devacc": 27.55, "acc": 28.29}, "11_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 9, "head_size": 64, "devacc": 28.48, "acc": 28.18}, "11_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 10, "head_size": 64, "devacc": 27.07, "acc": 27.26}, "11_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 11, "head_size": 64, "devacc": 27.53, "acc": 27.67}, "0_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 12, "head_size": 64, "devacc": 2.19, "acc": 2.31}, "0_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 13, "head_size": 64, "devacc": 2.25, "acc": 2.28}, "0_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 14, "head_size": 64, "devacc": 1.98, "acc": 1.89}, "0_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 15, "head_size": 64, "devacc": 2.19, "acc": 2.3}, "1_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 12, "head_size": 64, "devacc": 18.22, "acc": 18.17}, "1_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 13, "head_size": 64, "devacc": 17.64, "acc": 17.66}, "1_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 14, "head_size": 64, "devacc": 17.21, "acc": 16.8}, "1_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 15, "head_size": 64, "devacc": 17.4, "acc": 17.37}, "2_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 12, "head_size": 64, "devacc": 15.19, "acc": 15.99}, "2_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 13, "head_size": 64, "devacc": 16.38, "acc": 16.32}, "2_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 14, "head_size": 64, "devacc": 15.56, "acc": 15.69}, "2_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 15, "head_size": 64, "devacc": 14.43, "acc": 14.73}, "3_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 12, "head_size": 64, "devacc": 13.17, "acc": 13.56}, "3_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 13, "head_size": 64, "devacc": 14.77, "acc": 14.36}, "3_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 14, "head_size": 64, "devacc": 13.87, "acc": 13.8}, "3_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 15, "head_size": 64, "devacc": 12.46, "acc": 12.44}, "4_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 12, "head_size": 64, "devacc": 17.39, "acc": 17.47}, "4_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 13, "head_size": 64, "devacc": 18.66, "acc": 18.52}, "4_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 14, "head_size": 64, "devacc": 17.85, "acc": 17.61}, "4_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 15, "head_size": 64, "devacc": 17.25, "acc": 17.35}, "5_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 12, "head_size": 64, "devacc": 22.94, "acc": 22.69}, "5_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 13, "head_size": 64, "devacc": 23.55, "acc": 24.1}, "5_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 14, "head_size": 64, "devacc": 21.59, "acc": 21.34}, "5_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 15, "head_size": 64, "devacc": 21.83, "acc": 23.05}, "6_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 12, "head_size": 64, "devacc": 27.74, "acc": 28.01}, "6_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 13, "head_size": 64, "devacc": 28.73, "acc": 28.51}, "6_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 14, "head_size": 64, "devacc": 26.13, "acc": 26.25}, "6_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 15, "head_size": 64, "devacc": 26.9, "acc": 26.85}, "7_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 12, "head_size": 64, "devacc": 28.99, "acc": 28.74}, "7_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 13, "head_size": 64, "devacc": 29.06, "acc": 28.93}, "7_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 14, "head_size": 64, "devacc": 26.67, "acc": 26.94}, "7_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 15, "head_size": 64, "devacc": 28.5, "acc": 27.84}, "8_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 12, "head_size": 64, "devacc": 27.79, "acc": 26.75}, "8_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 13, "head_size": 64, "devacc": 28.29, "acc": 27.48}, "8_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 14, "head_size": 64, "devacc": 26.8, "acc": 26.82}, "8_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 15, "head_size": 64, "devacc": 28.32, "acc": 27.7}, "9_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 12, "head_size": 64, "devacc": 27.86, "acc": 27.45}, "9_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 13, "head_size": 64, "devacc": 29.18, "acc": 29.71}, "9_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 14, "head_size": 64, "devacc": 27.96, "acc": 28.9}, "9_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 15, "head_size": 64, "devacc": 30.0, "acc": 29.8}, "10_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 12, "head_size": 64, "devacc": 29.19, "acc": 28.49}, "10_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 13, "head_size": 64, "devacc": 30.36, "acc": 30.71}, "10_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 14, "head_size": 64, "devacc": 29.8, "acc": 29.3}, "10_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 15, "head_size": 64, "devacc": 30.37, "acc": 29.48}, "11_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 12, "head_size": 64, "devacc": 26.58, "acc": 26.41}, "11_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 13, "head_size": 64, "devacc": 27.97, "acc": 28.2}, "11_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 14, "head_size": 64, "devacc": 27.43, "acc": 26.92}, "11_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 15, "head_size": 64, "devacc": 27.34, "acc": 27.48}, "12_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": -1, "head_size": 64, "devacc": 28.03, "acc": 28.0}, "12_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 0, "head_size": 64, "devacc": 23.17, "acc": 23.26}, "12_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 1, "head_size": 64, "devacc": 21.0, "acc": 20.94}, "12_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 2, "head_size": 64, "devacc": 22.91, "acc": 22.71}, "12_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 3, "head_size": 64, "devacc": 23.11, "acc": 22.92}, "12_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 4, "head_size": 64, "devacc": 22.45, "acc": 23.19}, "12_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 5, "head_size": 64, "devacc": 22.83, "acc": 22.98}, "12_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 6, "head_size": 64, "devacc": 23.69, "acc": 24.08}, "12_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 7, "head_size": 64, "devacc": 19.73, "acc": 19.68}, "12_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 8, "head_size": 64, "devacc": 22.94, "acc": 23.28}, "12_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 9, "head_size": 64, "devacc": 23.81, "acc": 23.57}, "12_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 10, "head_size": 64, "devacc": 23.25, "acc": 23.46}, "12_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 11, "head_size": 64, "devacc": 23.41, "acc": 23.16}, "12_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 12, "head_size": 64, "devacc": 21.58, "acc": 21.71}, "12_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 13, "head_size": 64, "devacc": 22.87, "acc": 23.54}, "12_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 14, "head_size": 64, "devacc": 22.9, "acc": 22.42}, "12_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 15, "head_size": 64, "devacc": 22.59, "acc": 22.49}, "13_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": -1, "head_size": 64, "devacc": 22.36, "acc": 22.68}, "13_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 0, "head_size": 64, "devacc": 16.34, "acc": 16.13}, "13_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 1, "head_size": 64, "devacc": 14.83, "acc": 14.61}, "13_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 2, "head_size": 64, "devacc": 16.36, "acc": 16.23}, "13_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 3, "head_size": 64, "devacc": 16.8, "acc": 16.79}, "13_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 4, "head_size": 64, "devacc": 15.86, "acc": 16.47}, "13_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 5, "head_size": 64, "devacc": 16.03, "acc": 16.5}, "13_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 6, "head_size": 64, "devacc": 17.42, "acc": 17.24}, "13_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 7, "head_size": 64, "devacc": 14.78, "acc": 14.88}, "13_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 8, "head_size": 64, "devacc": 15.56, "acc": 16.18}, "13_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 9, "head_size": 64, "devacc": 17.26, "acc": 17.22}, "13_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 10, "head_size": 64, "devacc": 16.74, "acc": 17.27}, "13_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 11, "head_size": 64, "devacc": 15.92, "acc": 16.71}, "13_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 12, "head_size": 64, "devacc": 15.59, "acc": 15.32}, "13_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 13, "head_size": 64, "devacc": 16.2, "acc": 16.25}, "13_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 14, "head_size": 64, "devacc": 16.46, "acc": 15.89}, "13_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 15, "head_size": 64, "devacc": 16.58, "acc": 17.04}, "14_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": -1, "head_size": 64, "devacc": 22.64, "acc": 22.57}, "14_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 0, "head_size": 64, "devacc": 13.07, "acc": 13.13}, "14_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 1, "head_size": 64, "devacc": 12.81, "acc": 12.98}, "14_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 2, "head_size": 64, "devacc": 13.76, "acc": 13.68}, "14_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 3, "head_size": 64, "devacc": 14.95, "acc": 14.44}, "14_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 4, "head_size": 64, "devacc": 13.95, "acc": 13.72}, "14_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 5, "head_size": 64, "devacc": 13.97, "acc": 13.94}, "14_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 6, "head_size": 64, "devacc": 14.26, "acc": 14.16}, "14_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 7, "head_size": 64, "devacc": 13.52, "acc": 13.76}, "14_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 8, "head_size": 64, "devacc": 13.28, "acc": 13.81}, "14_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 9, "head_size": 64, "devacc": 14.91, "acc": 14.74}, "14_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 10, "head_size": 64, "devacc": 14.0, "acc": 14.63}, "14_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 11, "head_size": 64, "devacc": 13.8, "acc": 13.76}, "14_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 12, "head_size": 64, "devacc": 13.8, "acc": 13.71}, "14_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 13, "head_size": 64, "devacc": 13.47, "acc": 13.87}, "14_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 14, "head_size": 64, "devacc": 14.21, "acc": 13.47}, "14_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 15, "head_size": 64, "devacc": 14.17, "acc": 13.66}, "15_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": -1, "head_size": 64, "devacc": 17.61, "acc": 17.56}, "15_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 0, "head_size": 64, "devacc": 10.28, "acc": 10.11}, "15_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 1, "head_size": 64, "devacc": 10.37, "acc": 9.96}, "15_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 2, "head_size": 64, "devacc": 10.69, "acc": 10.59}, "15_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 3, "head_size": 64, "devacc": 11.14, "acc": 10.76}, "15_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 4, "head_size": 64, "devacc": 10.71, "acc": 10.43}, "15_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 5, "head_size": 64, "devacc": 10.45, "acc": 11.05}, "15_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 6, "head_size": 64, "devacc": 11.43, "acc": 11.34}, "15_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 7, "head_size": 64, "devacc": 10.96, "acc": 11.15}, "15_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 8, "head_size": 64, "devacc": 10.82, "acc": 10.37}, "15_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 9, "head_size": 64, "devacc": 11.81, "acc": 12.06}, "15_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 10, "head_size": 64, "devacc": 10.96, "acc": 11.02}, "15_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 11, "head_size": 64, "devacc": 10.66, "acc": 11.38}, "15_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 12, "head_size": 64, "devacc": 10.84, "acc": 11.1}, "15_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 13, "head_size": 64, "devacc": 10.62, "acc": 10.8}, "15_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 14, "head_size": 64, "devacc": 10.8, "acc": 10.43}, "15_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 15, "head_size": 64, "devacc": 11.01, "acc": 10.5}, "16_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": -1, "head_size": 64, "devacc": 17.66, "acc": 17.7}, "16_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 0, "head_size": 64, "devacc": 9.66, "acc": 10.04}, "16_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 1, "head_size": 64, "devacc": 10.58, "acc": 10.12}, "16_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 2, "head_size": 64, "devacc": 10.58, "acc": 10.33}, "16_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 3, "head_size": 64, "devacc": 11.06, "acc": 10.47}, "16_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 4, "head_size": 64, "devacc": 10.45, "acc": 10.41}, "16_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 5, "head_size": 64, "devacc": 10.67, "acc": 10.84}, "16_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 6, "head_size": 64, "devacc": 11.09, "acc": 10.92}, "16_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 7, "head_size": 64, "devacc": 10.92, "acc": 10.86}, "16_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 8, "head_size": 64, "devacc": 10.81, "acc": 10.38}, "16_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 9, "head_size": 64, "devacc": 11.29, "acc": 11.08}, "16_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 10, "head_size": 64, "devacc": 10.61, "acc": 10.88}, "16_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 11, "head_size": 64, "devacc": 10.41, "acc": 10.83}, "16_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 12, "head_size": 64, "devacc": 10.75, "acc": 10.42}, "16_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 13, "head_size": 64, "devacc": 10.85, "acc": 10.49}, "16_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 14, "head_size": 64, "devacc": 10.58, "acc": 10.33}, "16_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 15, "head_size": 64, "devacc": 10.87, "acc": 10.58}, "17_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": -1, "head_size": 64, "devacc": 16.8, "acc": 16.91}, "17_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 0, "head_size": 64, "devacc": 9.34, "acc": 9.29}, "17_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 1, "head_size": 64, "devacc": 9.98, "acc": 9.54}, "17_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 2, "head_size": 64, "devacc": 10.18, "acc": 9.88}, "17_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 3, "head_size": 64, "devacc": 10.28, "acc": 10.15}, "17_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 4, "head_size": 64, "devacc": 9.98, "acc": 9.94}, "17_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 5, "head_size": 64, "devacc": 10.26, "acc": 10.35}, "17_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 6, "head_size": 64, "devacc": 10.34, "acc": 10.33}, "17_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 7, "head_size": 64, "devacc": 10.0, "acc": 10.16}, "17_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 8, "head_size": 64, "devacc": 9.98, "acc": 9.79}, "17_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 9, "head_size": 64, "devacc": 10.59, "acc": 10.38}, "17_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 10, "head_size": 64, "devacc": 10.2, "acc": 10.09}, "17_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 11, "head_size": 64, "devacc": 9.83, "acc": 10.26}, "17_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 12, "head_size": 64, "devacc": 10.09, "acc": 9.67}, "17_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 13, "head_size": 64, "devacc": 10.59, "acc": 10.01}, "17_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 14, "head_size": 64, "devacc": 10.18, "acc": 10.03}, "17_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 15, "head_size": 64, "devacc": 9.97, "acc": 9.53}, "18_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": -1, "head_size": 64, "devacc": 16.87, "acc": 16.18}, "18_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 0, "head_size": 64, "devacc": 8.69, "acc": 8.7}, "18_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 1, "head_size": 64, "devacc": 9.5, "acc": 8.64}, "18_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 2, "head_size": 64, "devacc": 9.64, "acc": 8.76}, "18_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 3, "head_size": 64, "devacc": 9.84, "acc": 9.88}, "18_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 4, "head_size": 64, "devacc": 9.29, "acc": 9.13}, "18_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 5, "head_size": 64, "devacc": 9.86, "acc": 9.67}, "18_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 6, "head_size": 64, "devacc": 9.76, "acc": 9.75}, "18_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 7, "head_size": 64, "devacc": 9.44, "acc": 9.22}, "18_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 8, "head_size": 64, "devacc": 9.42, "acc": 9.22}, "18_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 9, "head_size": 64, "devacc": 9.98, "acc": 9.35}, "18_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 10, "head_size": 64, "devacc": 9.62, "acc": 10.0}, "18_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 11, "head_size": 64, "devacc": 9.23, "acc": 9.0}, "18_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 12, "head_size": 64, "devacc": 9.38, "acc": 9.3}, "18_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 13, "head_size": 64, "devacc": 9.88, "acc": 9.49}, "18_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 14, "head_size": 64, "devacc": 9.36, "acc": 9.4}, "18_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 15, "head_size": 64, "devacc": 9.65, "acc": 9.08}, "19_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": -1, "head_size": 64, "devacc": 18.37, "acc": 17.67}, "19_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 0, "head_size": 64, "devacc": 9.11, "acc": 9.23}, "19_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 1, "head_size": 64, "devacc": 9.87, "acc": 9.23}, "19_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 2, "head_size": 64, "devacc": 9.63, "acc": 9.44}, "19_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 3, "head_size": 64, "devacc": 10.04, "acc": 9.88}, "19_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 4, "head_size": 64, "devacc": 8.97, "acc": 9.38}, "19_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 5, "head_size": 64, "devacc": 10.23, "acc": 10.07}, "19_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 6, "head_size": 64, "devacc": 9.91, "acc": 9.59}, "19_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 7, "head_size": 64, "devacc": 9.11, "acc": 9.17}, "19_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 8, "head_size": 64, "devacc": 9.41, "acc": 9.08}, "19_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 9, "head_size": 64, "devacc": 10.02, "acc": 9.78}, "19_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 10, "head_size": 64, "devacc": 9.86, "acc": 10.21}, "19_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 11, "head_size": 64, "devacc": 9.86, "acc": 9.16}, "19_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 12, "head_size": 64, "devacc": 9.96, "acc": 9.32}, "19_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 13, "head_size": 64, "devacc": 9.86, "acc": 9.39}, "19_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 14, "head_size": 64, "devacc": 9.04, "acc": 8.93}, "19_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 15, "head_size": 64, "devacc": 9.56, "acc": 8.79}, "20_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": -1, "head_size": 64, "devacc": 17.81, "acc": 17.48}, "20_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 0, "head_size": 64, "devacc": 8.71, "acc": 9.06}, "20_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 1, "head_size": 64, "devacc": 9.05, "acc": 8.71}, "20_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 2, "head_size": 64, "devacc": 9.11, "acc": 8.95}, "20_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 3, "head_size": 64, "devacc": 9.42, "acc": 9.13}, "20_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 4, "head_size": 64, "devacc": 9.13, "acc": 8.89}, "20_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 5, "head_size": 64, "devacc": 9.66, "acc": 9.24}, "20_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 6, "head_size": 64, "devacc": 9.49, "acc": 9.21}, "20_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 7, "head_size": 64, "devacc": 8.6, "acc": 8.79}, "20_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 8, "head_size": 64, "devacc": 9.05, "acc": 8.91}, "20_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 9, "head_size": 64, "devacc": 9.05, "acc": 9.12}, "20_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 10, "head_size": 64, "devacc": 8.92, "acc": 9.15}, "20_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 11, "head_size": 64, "devacc": 9.02, "acc": 9.02}, "20_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 12, "head_size": 64, "devacc": 9.08, "acc": 8.6}, "20_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 13, "head_size": 64, "devacc": 9.34, "acc": 8.68}, "20_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 14, "head_size": 64, "devacc": 8.19, "acc": 8.09}, "20_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 15, "head_size": 64, "devacc": 9.14, "acc": 8.87}, "21_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": -1, "head_size": 64, "devacc": 18.06, "acc": 18.05}, "21_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 0, "head_size": 64, "devacc": 8.51, "acc": 8.65}, "21_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 1, "head_size": 64, "devacc": 8.72, "acc": 8.14}, "21_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 2, "head_size": 64, "devacc": 8.72, "acc": 8.63}, "21_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 3, "head_size": 64, "devacc": 9.18, "acc": 8.74}, "21_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 4, "head_size": 64, "devacc": 8.52, "acc": 8.35}, "21_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 5, "head_size": 64, "devacc": 9.14, "acc": 8.85}, "21_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 6, "head_size": 64, "devacc": 9.27, "acc": 8.78}, "21_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 7, "head_size": 64, "devacc": 8.58, "acc": 8.38}, "21_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 8, "head_size": 64, "devacc": 8.91, "acc": 8.29}, "21_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 9, "head_size": 64, "devacc": 8.89, "acc": 8.62}, "21_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 10, "head_size": 64, "devacc": 8.5, "acc": 8.23}, "21_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 11, "head_size": 64, "devacc": 8.46, "acc": 8.63}, "21_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 12, "head_size": 64, "devacc": 8.88, "acc": 8.45}, "21_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 13, "head_size": 64, "devacc": 8.72, "acc": 8.0}, "21_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 14, "head_size": 64, "devacc": 7.7, "acc": 7.57}, "21_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 15, "head_size": 64, "devacc": 8.87, "acc": 8.13}, "22_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": -1, "head_size": 64, "devacc": 16.51, "acc": 16.94}, "22_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 0, "head_size": 64, "devacc": 7.84, "acc": 8.01}, "22_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 1, "head_size": 64, "devacc": 8.35, "acc": 7.89}, "22_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 2, "head_size": 64, "devacc": 8.14, "acc": 8.32}, "22_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 3, "head_size": 64, "devacc": 8.16, "acc": 8.47}, "22_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 4, "head_size": 64, "devacc": 7.92, "acc": 8.35}, "22_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 5, "head_size": 64, "devacc": 8.39, "acc": 8.44}, "22_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 6, "head_size": 64, "devacc": 8.52, "acc": 8.21}, "22_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 7, "head_size": 64, "devacc": 8.05, "acc": 7.71}, "22_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 8, "head_size": 64, "devacc": 8.07, "acc": 7.92}, "22_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 9, "head_size": 64, "devacc": 8.27, "acc": 7.81}, "22_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 10, "head_size": 64, "devacc": 7.92, "acc": 8.28}, "22_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 11, "head_size": 64, "devacc": 7.68, "acc": 7.84}, "22_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 12, "head_size": 64, "devacc": 7.77, "acc": 7.61}, "22_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 13, "head_size": 64, "devacc": 7.99, "acc": 7.71}, "22_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 14, "head_size": 64, "devacc": 6.85, "acc": 6.62}, "22_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 15, "head_size": 64, "devacc": 8.12, "acc": 7.52}, "23_-1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": -1, "head_size": 64, "devacc": 12.68, "acc": 12.15}, "23_0": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 0, "head_size": 64, "devacc": 7.74, "acc": 8.11}, "23_1": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 1, "head_size": 64, "devacc": 8.22, "acc": 7.86}, "23_2": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 2, "head_size": 64, "devacc": 7.93, "acc": 8.03}, "23_3": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 3, "head_size": 64, "devacc": 8.4, "acc": 7.72}, "23_4": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 4, "head_size": 64, "devacc": 7.71, "acc": 7.75}, "23_5": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 5, "head_size": 64, "devacc": 8.03, "acc": 7.85}, "23_6": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 6, "head_size": 64, "devacc": 8.26, "acc": 7.53}, "23_7": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 7, "head_size": 64, "devacc": 7.53, "acc": 7.68}, "23_8": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 8, "head_size": 64, "devacc": 8.23, "acc": 8.05}, "23_9": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 9, "head_size": 64, "devacc": 7.64, "acc": 7.42}, "23_10": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 10, "head_size": 64, "devacc": 7.0, "acc": 7.57}, "23_11": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 11, "head_size": 64, "devacc": 7.29, "acc": 7.38}, "23_12": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 12, "head_size": 64, "devacc": 7.48, "acc": 7.96}, "23_13": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 13, "head_size": 64, "devacc": 7.77, "acc": 7.44}, "23_14": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 14, "head_size": 64, "devacc": 7.37, "acc": 7.67}, "23_15": {"device": ["3"], "batch_size": 500, "nhid": 0, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./results/", "optim": "rmsprop", "cbatch_size": 512, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 15, "head_size": 64, "devacc": 8.05, "acc": 6.99}}
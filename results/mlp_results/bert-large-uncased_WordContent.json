{"0_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 6.61, "acc": 6.71}, "1_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 42.53, "acc": 42.91}, "2_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 40.89, "acc": 40.77}, "3_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 39.02, "acc": 39.08}, "4_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 39.34, "acc": 39.37}, "5_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 44.64, "acc": 44.54}, "6_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 44.15, "acc": 43.15}, "7_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 42.95, "acc": 41.79}, "8_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 43.16, "acc": 42.93}, "9_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 41.86, "acc": 40.93}, "10_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 41.79, "acc": 42.15}, "11_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 38.35, "acc": 38.36}, "12_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 38.84, "acc": 38.4}, "13_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 35.55, "acc": 35.95}, "14_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 34.35, "acc": 33.88}, "15_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.59, "acc": 26.2}, "16_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.33, "acc": 26.63}, "17_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.61, "acc": 24.21}, "18_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.54, "acc": 23.49}, "19_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.94, "acc": 21.52}, "20_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.07, "acc": 22.09}, "21_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.46, "acc": 21.21}, "22_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 20.25, "acc": 20.25}, "23_-1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.59, "acc": 18.41}, "0_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.18, "acc": 2.04}, "1_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.35, "acc": 16.17}, "2_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.24, "acc": 15.64}, "3_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.6, "acc": 13.84}, "4_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.14, "acc": 18.72}, "5_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.3, "acc": 23.46}, "6_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.43, "acc": 28.12}, "7_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.54, "acc": 28.81}, "8_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.29, "acc": 28.15}, "9_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.09, "acc": 29.26}, "10_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.17, "acc": 30.08}, "11_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.5, "acc": 28.05}, "12_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.2, "acc": 23.2}, "13_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.43, "acc": 16.07}, "14_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.55, "acc": 13.08}, "15_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.83, "acc": 10.31}, "16_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.13, "acc": 10.04}, "17_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.63, "acc": 9.55}, "18_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.73, "acc": 8.91}, "19_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.01, "acc": 9.07}, "20_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.69, "acc": 8.59}, "21_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.65, "acc": 8.57}, "22_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.79, "acc": 7.76}, "23_0": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 0, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.54, "acc": 8.08}, "0_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.0, "acc": 2.04}, "1_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.08, "acc": 16.05}, "2_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.31, "acc": 14.07}, "3_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.26, "acc": 12.78}, "4_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.47, "acc": 16.63}, "5_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.41, "acc": 22.47}, "6_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.55, "acc": 26.55}, "7_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.74, "acc": 27.22}, "8_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.25, "acc": 26.49}, "9_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.89, "acc": 27.94}, "10_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.6, "acc": 28.74}, "11_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.34, "acc": 26.59}, "12_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.52, "acc": 21.32}, "13_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.02, "acc": 14.82}, "14_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 12.73, "acc": 12.73}, "15_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.41, "acc": 10.38}, "16_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.58, "acc": 10.08}, "17_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.79, "acc": 9.38}, "18_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.47, "acc": 8.74}, "19_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.7, "acc": 9.06}, "20_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.98, "acc": 8.55}, "21_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.73, "acc": 8.09}, "22_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.29, "acc": 7.65}, "23_1": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.25, "acc": 7.76}, "0_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.17, "acc": 1.02}, "1_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.28, "acc": 11.4}, "2_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.06, "acc": 10.21}, "3_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.2, "acc": 8.75}, "4_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.0, "acc": 14.63}, "5_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.77, "acc": 22.21}, "6_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.2, "acc": 27.79}, "7_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.77, "acc": 27.53}, "8_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.84, "acc": 27.85}, "9_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.71, "acc": 29.11}, "10_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.96, "acc": 29.78}, "11_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.52, "acc": 27.85}, "12_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.08, "acc": 23.0}, "13_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.47, "acc": 16.34}, "14_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.43, "acc": 13.21}, "15_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.72, "acc": 10.69}, "16_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.72, "acc": 10.47}, "17_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.99, "acc": 10.0}, "18_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.5, "acc": 8.5}, "19_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.55, "acc": 9.34}, "20_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.96, "acc": 8.68}, "21_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.55, "acc": 8.31}, "22_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.07, "acc": 8.17}, "23_2": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 2, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.78, "acc": 8.33}, "0_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.94, "acc": 1.77}, "1_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.66, "acc": 17.84}, "2_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.15, "acc": 16.44}, "3_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 12.47, "acc": 12.36}, "4_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.8, "acc": 16.74}, "5_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.11, "acc": 21.53}, "6_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.07, "acc": 26.69}, "7_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.62, "acc": 26.74}, "8_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.21, "acc": 27.45}, "9_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.71, "acc": 28.09}, "10_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.09, "acc": 29.42}, "11_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.85, "acc": 27.42}, "12_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.05, "acc": 22.32}, "13_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.74, "acc": 16.37}, "14_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.78, "acc": 13.8}, "15_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.22, "acc": 10.61}, "16_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.96, "acc": 10.46}, "17_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.19, "acc": 10.04}, "18_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.83, "acc": 9.36}, "19_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.93, "acc": 9.93}, "20_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.23, "acc": 9.15}, "21_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.86, "acc": 8.49}, "22_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.09, "acc": 8.29}, "23_3": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 3, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.21, "acc": 7.67}, "0_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.1, "acc": 2.0}, "1_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.52, "acc": 16.85}, "2_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.89, "acc": 15.04}, "3_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.84, "acc": 13.64}, "4_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 19.05, "acc": 18.64}, "5_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.77, "acc": 23.01}, "6_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.03, "acc": 27.12}, "7_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.37, "acc": 28.01}, "8_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.21, "acc": 27.32}, "9_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.19, "acc": 28.97}, "10_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.12, "acc": 29.6}, "11_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.22, "acc": 28.12}, "12_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.57, "acc": 23.29}, "13_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.76, "acc": 16.47}, "14_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.89, "acc": 13.56}, "15_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.79, "acc": 10.32}, "16_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.45, "acc": 10.38}, "17_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.04, "acc": 9.88}, "18_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.19, "acc": 9.09}, "19_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.88, "acc": 9.3}, "20_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.95, "acc": 8.65}, "21_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.38, "acc": 8.31}, "22_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.62, "acc": 7.94}, "23_4": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 4, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.5, "acc": 7.94}, "0_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.94, "acc": 2.23}, "1_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.25, "acc": 17.13}, "2_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.18, "acc": 15.23}, "3_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.65, "acc": 14.49}, "4_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.57, "acc": 18.18}, "5_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 24.03, "acc": 23.36}, "6_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.31, "acc": 28.44}, "7_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.56, "acc": 27.78}, "8_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.32, "acc": 28.06}, "9_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.28, "acc": 29.63}, "10_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.56, "acc": 29.46}, "11_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.49, "acc": 28.11}, "12_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.9, "acc": 23.22}, "13_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.98, "acc": 16.4}, "14_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.03, "acc": 14.01}, "15_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.0, "acc": 11.2}, "16_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.69, "acc": 10.85}, "17_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.25, "acc": 10.21}, "18_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.88, "acc": 9.5}, "19_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.01, "acc": 9.9}, "20_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.32, "acc": 9.5}, "21_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.74, "acc": 8.74}, "22_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.35, "acc": 8.21}, "23_5": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 5, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.95, "acc": 7.9}, "0_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.08, "acc": 2.27}, "1_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.65, "acc": 18.03}, "2_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.47, "acc": 16.71}, "3_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.28, "acc": 14.15}, "4_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.53, "acc": 18.84}, "5_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.51, "acc": 23.56}, "6_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.55, "acc": 28.54}, "7_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.41, "acc": 29.33}, "8_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.51, "acc": 27.87}, "9_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.14, "acc": 29.05}, "10_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.9, "acc": 29.86}, "11_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.82, "acc": 27.95}, "12_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.82, "acc": 24.24}, "13_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.32, "acc": 17.33}, "14_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.33, "acc": 14.12}, "15_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.42, "acc": 11.2}, "16_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.98, "acc": 10.68}, "17_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.36, "acc": 10.45}, "18_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.8, "acc": 9.71}, "19_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.76, "acc": 9.6}, "20_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.46, "acc": 9.11}, "21_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.11, "acc": 8.74}, "22_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.51, "acc": 7.9}, "23_6": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 6, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.89, "acc": 7.81}, "0_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.12, "acc": 1.9}, "1_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.79, "acc": 17.79}, "2_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.97, "acc": 16.29}, "3_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.82, "acc": 13.8}, "4_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.22, "acc": 17.94}, "5_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.61, "acc": 22.45}, "6_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.25, "acc": 25.05}, "7_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.41, "acc": 24.9}, "8_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.33, "acc": 24.82}, "9_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.41, "acc": 26.45}, "10_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.7, "acc": 27.84}, "11_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 25.49, "acc": 25.75}, "12_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.19, "acc": 21.13}, "13_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.36, "acc": 15.49}, "14_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.66, "acc": 13.49}, "15_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.98, "acc": 11.04}, "16_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.68, "acc": 11.0}, "17_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.17, "acc": 9.93}, "18_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.34, "acc": 9.19}, "19_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.99, "acc": 9.21}, "20_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.62, "acc": 8.7}, "21_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.7, "acc": 8.3}, "22_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.9, "acc": 7.74}, "23_7": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 7, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.55, "acc": 7.7}, "0_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.05, "acc": 2.16}, "1_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.89, "acc": 16.93}, "2_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.4, "acc": 16.98}, "3_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.3, "acc": 13.5}, "4_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.92, "acc": 18.85}, "5_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.02, "acc": 23.13}, "6_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.97, "acc": 28.35}, "7_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.66, "acc": 28.69}, "8_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.47, "acc": 27.72}, "9_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.77, "acc": 29.5}, "10_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.26, "acc": 29.67}, "11_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.52, "acc": 28.6}, "12_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.75, "acc": 23.11}, "13_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.6, "acc": 16.22}, "14_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.53, "acc": 13.85}, "15_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.51, "acc": 10.48}, "16_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.87, "acc": 10.55}, "17_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.91, "acc": 9.66}, "18_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.37, "acc": 8.96}, "19_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.33, "acc": 8.91}, "20_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.96, "acc": 8.75}, "21_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.96, "acc": 8.34}, "22_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.0, "acc": 7.67}, "23_8": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 8, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.07, "acc": 7.91}, "0_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.1, "acc": 2.19}, "1_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.31, "acc": 17.58}, "2_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.04, "acc": 15.14}, "3_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.28, "acc": 13.49}, "4_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.6, "acc": 18.09}, "5_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.21, "acc": 23.28}, "6_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.57, "acc": 27.81}, "7_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.97, "acc": 28.65}, "8_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.22, "acc": 28.33}, "9_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.71, "acc": 29.49}, "10_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.62, "acc": 30.86}, "11_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.1, "acc": 28.86}, "12_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 24.55, "acc": 24.42}, "13_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.59, "acc": 17.61}, "14_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.01, "acc": 14.67}, "15_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.76, "acc": 11.15}, "16_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 11.18, "acc": 10.9}, "17_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.59, "acc": 10.29}, "18_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.88, "acc": 9.1}, "19_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.9, "acc": 9.64}, "20_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.19, "acc": 9.01}, "21_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.77, "acc": 8.49}, "22_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.25, "acc": 7.58}, "23_9": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 9, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.78, "acc": 7.4}, "0_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.2, "acc": 2.3}, "1_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.01, "acc": 16.22}, "2_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.85, "acc": 14.68}, "3_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 12.94, "acc": 11.95}, "4_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.99, "acc": 17.52}, "5_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.75, "acc": 23.7}, "6_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.96, "acc": 26.69}, "7_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.88, "acc": 27.78}, "8_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.2, "acc": 26.81}, "9_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.3, "acc": 28.82}, "10_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.31, "acc": 29.21}, "11_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.4, "acc": 27.59}, "12_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.4, "acc": 23.48}, "13_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.6, "acc": 16.71}, "14_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.91, "acc": 14.05}, "15_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.94, "acc": 10.94}, "16_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.55, "acc": 10.65}, "17_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.14, "acc": 9.98}, "18_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.78, "acc": 9.61}, "19_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.76, "acc": 9.79}, "20_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.77, "acc": 8.99}, "21_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.46, "acc": 8.56}, "22_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.01, "acc": 7.56}, "23_10": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 10, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.19, "acc": 7.53}, "0_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.23, "acc": 2.21}, "1_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.23, "acc": 18.17}, "2_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.16, "acc": 15.68}, "3_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.75, "acc": 13.78}, "4_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.73, "acc": 18.26}, "5_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.06, "acc": 23.11}, "6_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.16, "acc": 27.68}, "7_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.34, "acc": 28.01}, "8_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.96, "acc": 27.5}, "9_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.03, "acc": 29.04}, "10_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.76, "acc": 29.58}, "11_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.4, "acc": 27.74}, "12_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.92, "acc": 22.79}, "13_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.15, "acc": 16.43}, "14_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.7, "acc": 13.92}, "15_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.57, "acc": 10.92}, "16_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.62, "acc": 10.94}, "17_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.77, "acc": 10.08}, "18_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.21, "acc": 9.31}, "19_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.76, "acc": 9.34}, "20_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.9, "acc": 8.63}, "21_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.11, "acc": 8.36}, "22_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.67, "acc": 7.72}, "23_11": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 11, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.24, "acc": 7.3}, "0_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.06, "acc": 2.34}, "1_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.05, "acc": 18.19}, "2_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.97, "acc": 15.92}, "3_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.02, "acc": 13.0}, "4_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.77, "acc": 17.72}, "5_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.73, "acc": 22.95}, "6_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.12, "acc": 28.49}, "7_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.02, "acc": 28.86}, "8_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.04, "acc": 27.29}, "9_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.44, "acc": 27.99}, "10_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.36, "acc": 28.88}, "11_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 26.94, "acc": 26.74}, "12_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 21.98, "acc": 21.68}, "13_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.94, "acc": 15.56}, "14_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.74, "acc": 13.97}, "15_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.72, "acc": 10.62}, "16_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.68, "acc": 10.37}, "17_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.0, "acc": 10.15}, "18_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.45, "acc": 9.47}, "19_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.82, "acc": 9.27}, "20_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.93, "acc": 8.42}, "21_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.89, "acc": 8.28}, "22_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.73, "acc": 7.53}, "23_12": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 12, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.44, "acc": 7.7}, "0_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.05, "acc": 2.05}, "1_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.08, "acc": 17.24}, "2_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.92, "acc": 15.94}, "3_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.72, "acc": 13.11}, "4_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.72, "acc": 18.46}, "5_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.77, "acc": 24.3}, "6_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.0, "acc": 28.93}, "7_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.53, "acc": 29.06}, "8_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.53, "acc": 28.52}, "9_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.23, "acc": 29.82}, "10_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.57, "acc": 30.88}, "11_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.03, "acc": 28.46}, "12_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.76, "acc": 23.07}, "13_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.17, "acc": 16.7}, "14_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.45, "acc": 13.78}, "15_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.62, "acc": 10.15}, "16_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.92, "acc": 10.34}, "17_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.47, "acc": 9.9}, "18_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.87, "acc": 9.39}, "19_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.92, "acc": 8.84}, "20_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.35, "acc": 8.62}, "21_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.85, "acc": 7.96}, "22_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.05, "acc": 7.72}, "23_13": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 13, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.78, "acc": 7.31}, "0_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 1.81, "acc": 1.95}, "1_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.61, "acc": 16.26}, "2_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.83, "acc": 15.27}, "3_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.81, "acc": 13.56}, "4_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 18.09, "acc": 17.61}, "5_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.36, "acc": 22.46}, "6_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.23, "acc": 27.16}, "7_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.65, "acc": 27.78}, "8_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.7, "acc": 27.03}, "9_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.38, "acc": 28.77}, "10_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.16, "acc": 29.9}, "11_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.75, "acc": 27.33}, "12_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 23.07, "acc": 22.89}, "13_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.7, "acc": 15.96}, "14_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.31, "acc": 14.09}, "15_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.89, "acc": 11.07}, "16_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.52, "acc": 10.38}, "17_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.18, "acc": 9.79}, "18_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.25, "acc": 9.49}, "19_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.23, "acc": 8.92}, "20_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.3, "acc": 8.05}, "21_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.88, "acc": 8.03}, "22_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.36, "acc": 7.16}, "23_14": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 14, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.46, "acc": 7.75}, "0_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 0, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 2.31, "acc": 2.29}, "1_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 1, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.6, "acc": 16.59}, "2_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 2, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 14.56, "acc": 15.09}, "3_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 3, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 12.61, "acc": 12.61}, "4_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 4, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 17.4, "acc": 17.61}, "5_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 5, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.13, "acc": 23.17}, "6_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 6, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.09, "acc": 27.51}, "7_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 7, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.75, "acc": 27.95}, "8_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 8, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 28.5, "acc": 27.17}, "9_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 9, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 29.56, "acc": 28.96}, "10_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 10, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 30.39, "acc": 29.64}, "11_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 11, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 27.58, "acc": 27.51}, "12_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 12, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 22.71, "acc": 22.69}, "13_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 13, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 16.42, "acc": 16.45}, "14_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 14, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 13.78, "acc": 13.31}, "15_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 15, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.87, "acc": 10.58}, "16_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 16, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.72, "acc": 10.04}, "17_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 17, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 10.06, "acc": 9.49}, "18_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 18, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.68, "acc": 8.92}, "19_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 19, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 9.58, "acc": 8.61}, "20_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 20, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.93, "acc": 8.73}, "21_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 21, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 8.72, "acc": 7.87}, "22_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 22, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.9, "acc": 7.5}, "23_15": {"device": ["1"], "batch_size": 500, "nhid": 50, "kfold": 5, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./mlp_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "layer": 23, "head": 15, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 7.86, "acc": 6.91}}
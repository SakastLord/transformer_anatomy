{"0_0_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 0, "head": 0, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 17.86, "acc": 18.32}, "0_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 0, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 17.89, "acc": 18.42}, "1_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 1, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 30.97, "acc": 30.76}, "2_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 2, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 24.19, "acc": 24.11}, "3_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 3, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 23.51, "acc": 22.95}, "4_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 4, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 24.1, "acc": 24.38}, "5_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 5, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 22.33, "acc": 22.31}, "6_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 6, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 21.66, "acc": 20.15}, "7_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 7, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 24.15, "acc": 24.55}, "8_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 8, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 23.43, "acc": 22.82}, "9_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 9, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 22.56, "acc": 22.21}, "10_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 10, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 28.89, "acc": 28.58}, "11_-1_fc": {"device": ["0"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "WordContent", "layer": 11, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 35.97, "acc": 35.28}}
{"0_0_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 0, "head": 0, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 66.74, "acc": 66.56}, "0_1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 0, "head": 1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 62.46, "acc": 63.6}, "0_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 0, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 72.08, "acc": 71.78}, "1_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 1, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 74.64, "acc": 73.55}, "2_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 2, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 73.84, "acc": 72.8}, "3_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 3, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 73.75, "acc": 72.04}, "4_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 4, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 75.33, "acc": 73.17}, "5_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 5, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 76.58, "acc": 74.37}, "6_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 6, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 74.09, "acc": 71.55}, "7_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 7, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 74.23, "acc": 71.28}, "8_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 8, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 76.78, "acc": 73.87}, "9_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 9, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 73.7, "acc": 71.33}, "10_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 10, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 77.67, "acc": 75.22}, "11_-1_fc": {"device": ["6"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "openai-gpt", "task": "SubjNumber", "layer": 11, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 80.72, "acc": 78.81}}
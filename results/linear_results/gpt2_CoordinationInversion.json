{"0_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 0, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 51.18, "acc": 51.16}, "1_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 1, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 52.06, "acc": 52.24}, "2_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 2, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 52.86, "acc": 53.0}, "3_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 3, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 54.02, "acc": 53.73}, "4_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 4, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 54.02, "acc": 54.31}, "5_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 5, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 54.26, "acc": 54.27}, "6_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 6, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 54.85, "acc": 54.83}, "7_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 7, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 55.9, "acc": 56.06}, "8_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 8, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 57.08, "acc": 57.15}, "9_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 9, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 58.64, "acc": 58.94}, "10_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 10, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 59.77, "acc": 60.04}, "11_-1_fc": {"device": ["1"], "batch_size": 2000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./linear_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "CoordinationInversion", "layer": 11, "head": -1, "location": "fc", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "devacc": 58.61, "acc": 58.34}}
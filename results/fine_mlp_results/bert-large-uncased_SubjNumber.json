{"0_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 80.59, "acc": 78.77}, "1_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 82.56, "acc": 80.93}, "2_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 82.36, "acc": 81.82}, "3_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 83.57, "acc": 83.45}, "4_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 82.87, "acc": 83.31}, "5_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 83.09, "acc": 82.79}, "6_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 83.56, "acc": 83.15}, "7_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 83.95, "acc": 83.41}, "8_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 83.67, "acc": 83.25}, "9_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 84.96, "acc": 84.97}, "10_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 85.28, "acc": 85.03}, "11_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 86.74, "acc": 87.43}, "12_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 12, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 88.48, "acc": 88.36}, "13_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 13, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 88.9, "acc": 89.65}, "14_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 14, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 89.09, "acc": 89.92}, "15_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 15, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 88.6, "acc": 88.93}, "16_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 16, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 87.88, "acc": 88.28}, "17_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 17, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 86.9, "acc": 87.21}, "18_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 18, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 86.29, "acc": 86.46}, "19_-1": {"device": ["6"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 19, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 85.08, "acc": 85.61}, "20_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 20, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 84.17, "acc": 84.28}, "21_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 21, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 83.53, "acc": 83.44}, "22_-1": {"device": ["6"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 22, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 82.73, "acc": 82.23}, "23_-1": {"device": ["6"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-large-uncased", "task": "SubjNumber", "layer": 23, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 82.44, "acc": 81.82}}
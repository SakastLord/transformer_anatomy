{"16_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 16, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14]], "devacc": 80.48, "acc": 79.75}, "4_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 4, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5]], "devacc": 79.15, "acc": 79.42}, "8_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 8, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13]], "devacc": 80.44, "acc": 79.46}, "12_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 12, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8]], "devacc": 80.32, "acc": 79.71}, "20_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 20, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15]], "devacc": 79.9, "acc": 79.5}, "24_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 24, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14]], "devacc": 79.6, "acc": 79.41}, "28_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 28, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6]], "devacc": 78.28, "acc": 77.79}, "32_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 32, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8]], "devacc": 76.77, "acc": 76.36}, "36_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 36, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6]], "devacc": 77.55, "acc": 77.25}, "40_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 40, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9]], "devacc": 77.2, "acc": 76.98}, "44_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 44, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2]], "devacc": 77.46, "acc": 77.45}, "48_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 48, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10]], "devacc": 77.25, "acc": 76.55}, "52_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 52, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10], [1, 0], [6, 1], [12, 14], [5, 14]], "devacc": 77.77, "acc": 77.24}, "56_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 56, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10], [1, 0], [6, 1], [12, 14], [5, 14], [8, 12], [9, 3], [13, 2], [14, 4]], "devacc": 77.87, "acc": 77.33}, "60_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 60, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10], [1, 0], [6, 1], [12, 14], [5, 14], [8, 12], [9, 3], [13, 2], [14, 4], [9, 0], [9, 2], [8, 10], [8, 1]], "devacc": 74.55, "acc": 74.38}, "64_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 64, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10], [1, 0], [6, 1], [12, 14], [5, 14], [8, 12], [9, 3], [13, 2], [14, 4], [9, 0], [9, 2], [8, 10], [8, 1], [4, 10], [7, 15], [9, 15], [13, 0]], "devacc": 77.68, "acc": 77.49}, "68_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 68, "intv_head": 4, "total_head": 384, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7], [10, 12], [10, 8], [11, 5], [6, 4], [1, 10], [1, 14], [9, 4], [7, 5], [14, 3], [5, 15], [6, 5], [8, 5], [9, 8], [4, 14], [10, 15], [9, 13], [11, 0], [16, 6], [6, 6], [9, 12], [12, 6], [5, 8], [7, 8], [2, 8], [6, 14], [0, 6], [5, 11], [11, 8], [0, 12], [2, 9], [8, 11], [4, 6], [8, 3], [8, 2], [5, 6], [5, 9], [13, 3], [2, 10], [1, 0], [6, 1], [12, 14], [5, 14], [8, 12], [9, 3], [13, 2], [14, 4], [9, 0], [9, 2], [8, 10], [8, 1], [4, 10], [7, 15], [9, 15], [13, 0], [0, 4], [6, 3], [5, 1], [2, 15]], "devacc": 77.72, "acc": 77.27}, "1_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 1, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5]], "devacc": 53.22, "acc": 53.18}, "2_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 2, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15]], "devacc": 69.42, "acc": 69.39}, "3_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 3, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13]], "devacc": 75.99, "acc": 75.48}, "5_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 5, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2]], "devacc": 82.46, "acc": 82.45}, "6_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 6, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6]], "devacc": 81.0, "acc": 80.38}, "7_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 7, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10]], "devacc": 80.09, "acc": 79.42}, "9_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 9, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8]], "devacc": 81.82, "acc": 80.88}, "10_head": {"device": ["1"], "batch_size": 1000, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "bert-large-uncased", "task": "WordContent", "num_head": 10, "intv_head": 1, "total_head": 20, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[1, 5], [1, 15], [1, 13], [5, 5], [4, 2], [8, 6], [10, 10], [7, 13], [4, 8], [1, 7]], "devacc": 82.82, "acc": 81.67}}
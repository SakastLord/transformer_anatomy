{"0_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 15.51, "acc": 16.03}, "1_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 44.09, "acc": 44.62}, "2_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 49.11, "acc": 49.22}, "3_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 57.53, "acc": 57.61}, "4_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 56.43, "acc": 56.24}, "5_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 52.88, "acc": 52.3}, "6_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 41.44, "acc": 41.24}, "7_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 34.95, "acc": 34.89}, "8_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 34.18, "acc": 33.52}, "9_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 32.17, "acc": 31.84}, "10_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 33.29, "acc": 32.92}, "11_-1": {"device": ["3"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "WordContent", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 40.18, "acc": 40.39}}
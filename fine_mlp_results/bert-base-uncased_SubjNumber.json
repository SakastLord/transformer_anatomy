{"0_-1": {"device": ["2"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 0, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 80.12, "acc": 78.3}, "1_-1": {"device": ["2"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 1, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 83.46, "acc": 82.63}, "2_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 2, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 83.54, "acc": 82.53}, "3_-1": {"device": ["2"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 3, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.0, "devacc": 84.65, "acc": 84.19}, "4_-1": {"device": ["2"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 4, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 86.88, "acc": 86.81}, "5_-1": {"device": ["2"], "batch_size": 500, "nhid": 200, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 5, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 88.49, "acc": 88.3}, "6_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 6, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 87.9, "acc": 87.44}, "7_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 7, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 87.48, "acc": 87.16}, "8_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 8, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 87.8, "acc": 87.73}, "9_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 9, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 86.88, "acc": 86.79}, "10_-1": {"device": ["2"], "batch_size": 500, "nhid": 50, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 10, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.1, "devacc": 84.71, "acc": 85.02}, "11_-1": {"device": ["2"], "batch_size": 500, "nhid": 100, "kfold": 10, "usepytorch": true, "data_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./fine_mlp_results/", "optim": "adam", "cbatch_size": 64, "tenacity": 5, "epoch_size": 4, "model_name": "bert-base-uncased", "task": "SubjNumber", "layer": 11, "head": -1, "head_size": 64, "seed": 123, "dropout": 0.2, "devacc": 84.87, "acc": 84.31}}
{"12_head": {"device": ["2"], "batch_size": 100, "kfold": 5, "usepytorch": true, "task_path": "./SentEval/data/", "cache_path": "./cache/", "result_path": "./top_head_wise_results/", "optim": "rmsprop", "cbatch_size": 256, "tenacity": 3, "epoch_size": 2, "model_name": "gpt2", "task": "WordContent", "num_head": 12, "location": "head", "head_size": 64, "dropout": 0, "nhid": 0, "seed": 123, "classifier": {"nhid": 0, "optim": "rmsprop", "tenacity": 3, "epoch_size": 2, "dropout": 0, "batch_size": 256}, "heads": [[0, 6], [11, 3], [1, 7], [11, 11], [2, 1], [11, 9], [9, 2], [10, 0], [10, 6], [2, 9], [0, 0], [10, 1]], "devacc": 70.45, "acc": 71.0}}